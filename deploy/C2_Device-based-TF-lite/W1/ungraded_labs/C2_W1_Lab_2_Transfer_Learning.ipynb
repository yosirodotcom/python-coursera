{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-2-public/blob/adding_C2/C2/W1/ungraded_labs/C2_W1_Lab_2_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8-Nr5k11fh"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Eq10uEbw0E4l"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYM61xrTsP5d"
      },
      "source": [
        "# Transfer Learning with TensorFlow Hub for TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL54LWCHt5q5"
      },
      "source": [
        "## Setup "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "110fGB18UNJn"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dlauq-4FWGZM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ASUS\\Documents\\pythonenv\\python-coursera\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'resource'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\ASUS\\Documents\\repos\\python-coursera\\deploy\\C2_Device-based-TF-lite\\W1\\ungraded_labs\\C2_W1_Lab_2_Transfer_Learning.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/repos/python-coursera/deploy/C2_Device-based-TF-lite/W1/ungraded_labs/C2_W1_Lab_2_Transfer_Learning.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/repos/python-coursera/deploy/C2_Device-based-TF-lite/W1/ungraded_labs/C2_W1_Lab_2_Transfer_Learning.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhub\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/repos/python-coursera/deploy/C2_Device-based-TF-lite/W1/ungraded_labs/C2_W1_Lab_2_Transfer_Learning.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfds\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/repos/python-coursera/deploy/C2_Device-based-TF-lite/W1/ungraded_labs/C2_W1_Lab_2_Transfer_Learning.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tfds\u001b[39m.\u001b[39mdisable_progress_bar()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/repos/python-coursera/deploy/C2_Device-based-TF-lite/W1/ungraded_labs/C2_W1_Lab_2_Transfer_Learning.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\pythonenv\\python-coursera\\lib\\site-packages\\tensorflow_datasets\\__init__.py:43\u001b[0m\n\u001b[0;32m     41\u001b[0m _TIMESTAMP_IMPORT_STARTS \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mabsl\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[1;32m---> 43\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogging\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_tfds_logging\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogging\u001b[39;00m \u001b[39mimport\u001b[39;00m call_metadata \u001b[39mas\u001b[39;00m _call_metadata\n\u001b[0;32m     46\u001b[0m _metadata \u001b[39m=\u001b[39m _call_metadata\u001b[39m.\u001b[39mCallMetadata()\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\pythonenv\\python-coursera\\lib\\site-packages\\tensorflow_datasets\\core\\__init__.py:22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m# Allow to use `tfds.core.Path` in dataset implementation which seems more\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m# natural than having to import a third party module.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39metils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mepath\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m community\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_builder\u001b[39;00m \u001b[39mimport\u001b[39;00m BeamBasedBuilder\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_builder\u001b[39;00m \u001b[39mimport\u001b[39;00m BuilderConfig\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\pythonenv\\python-coursera\\lib\\site-packages\\tensorflow_datasets\\core\\community\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# coding=utf-8\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Copyright 2023 The TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m\"\"\"Community dataset API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommunity\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhuggingface_wrapper\u001b[39;00m \u001b[39mimport\u001b[39;00m mock_builtin_to_use_gfile\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommunity\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhuggingface_wrapper\u001b[39;00m \u001b[39mimport\u001b[39;00m mock_huggingface_import\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommunity\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mload\u001b[39;00m \u001b[39mimport\u001b[39;00m builder_cls_from_module\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\pythonenv\\python-coursera\\lib\\site-packages\\tensorflow_datasets\\core\\community\\huggingface_wrapper.py:31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39munittest\u001b[39;00m \u001b[39mimport\u001b[39;00m mock\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39metils\u001b[39;00m \u001b[39mimport\u001b[39;00m epath\n\u001b[1;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m dataset_builder\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m dataset_info\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m download\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\pythonenv\\python-coursera\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m reader \u001b[39mas\u001b[39;00m reader_lib\n\u001b[0;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m registered\n\u001b[1;32m---> 44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m split_builder \u001b[39mas\u001b[39;00m split_builder_lib\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m splits \u001b[39mas\u001b[39;00m splits_lib\n\u001b[0;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_compat\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\pythonenv\\python-coursera\\lib\\site-packages\\tensorflow_datasets\\core\\split_builder.py:37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m splits \u001b[39mas\u001b[39;00m splits_lib\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m writer \u001b[39mas\u001b[39;00m writer_lib\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m shard_utils\n\u001b[0;32m     40\u001b[0m \u001b[39mif\u001b[39;00m typing\u001b[39m.\u001b[39mTYPE_CHECKING:\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\pythonenv\\python-coursera\\lib\\site-packages\\tensorflow_datasets\\core\\writer.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m lazy_imports_lib\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m naming\n\u001b[1;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m shuffle\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m file_utils\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\pythonenv\\python-coursera\\lib\\site-packages\\tensorflow_datasets\\core\\shuffle.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mresource\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstruct\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Iterator, List, Optional\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'resource'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)\n",
        "print(\"\\u2022 Using TensorFlow Hub Version: \", hub.__version__)\n",
        "print('\\u2022 GPU Device Found.' if tf.test.is_gpu_available() else '\\u2022 GPU Device Not Found. Running on CPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-datasets in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (4.9.3)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: absl-py in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (1.0.0)\n",
            "Requirement already satisfied: array-record in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from tensorflow-datasets) (0.4.1)\n",
            "Requirement already satisfied: click in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from tensorflow-datasets) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from tensorflow-datasets) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from tensorflow-datasets) (1.5.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from tensorflow-datasets) (1.26.0)\n",
            "Requirement already satisfied: promise in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from tensorflow-datasets) (3.20.3)\n",
            "Requirement already satisfied: psutil in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from tensorflow-datasets) (5.9.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from tensorflow-datasets) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from tensorflow-datasets) (1.14.0)\n",
            "Requirement already satisfied: termcolor in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (1.1.0)\n",
            "Requirement already satisfied: toml in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from tensorflow-datasets) (4.66.1)\n",
            "Requirement already satisfied: wrapt in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-datasets) (1.13.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (2023.10.0)\n",
            "Requirement already satisfied: importlib_resources in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (6.1.0)\n",
            "Requirement already satisfied: typing_extensions in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (4.8.0)\n",
            "Requirement already satisfied: zipp in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2021.10.8)\n",
            "Requirement already satisfied: six in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from absl-py->tensorflow-datasets) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from click->tensorflow-datasets) (0.4.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\asus\\documents\\pythonenv\\python-coursera\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.61.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade tensorflow-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmaHHH7Pvmth"
      },
      "source": [
        "## Select the Hub/TF2 Module to Use\n",
        "\n",
        "Hub modules for TF 1.x won't work here, please use one of the selections provided. \n",
        "\n",
        "This code gets the mobile net V-2 model from TensorFlow hub, and it prints out the details about it. Most important is the input size, that we can see is 224 by 224."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlsEcKVeuCnf"
      },
      "outputs": [],
      "source": [
        "module_selection = (\"mobilenet_v2\", 224, 1280) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYUsgwCBv87A"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nqVX3KYwGPh"
      },
      "source": [
        "Use [TensorFlow Datasets](http://tensorflow.org/datasets) to load the cats and dogs dataset.\n",
        "\n",
        "This `tfds` package is the easiest way to load pre-defined data. If you have your own data, and are interested in importing using it with TensorFlow see [loading image data](../load_data/images.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkF4Boe5wN7N"
      },
      "source": [
        "The `tfds.load` method downloads and caches the data, and returns a `tf.data.Dataset` object. These objects provide powerful, efficient methods for manipulating data and piping it into your model.\n",
        "\n",
        "Since `\"cats_vs_dog\"` only has one defined split, `train`, we are going to divide that into (train, validation, test) with 80%, 10%, 10% of the data respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ9xK9F2wGD8"
      },
      "outputs": [],
      "source": [
        "(train_examples, validation_examples, test_examples), info = tfds.load('cats_vs_dogs', \n",
        "                                                                       with_info=True, \n",
        "                                                                       as_supervised=True, \n",
        "                                                                       split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'])\n",
        "\n",
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXQYXNWwf19"
      },
      "source": [
        "### Format the Data\n",
        "\n",
        "Use the `tf.image` module to format the images for the task.\n",
        "\n",
        "Resize the images to a fixes input size, and rescale the input channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7UyXblSwkUS"
      },
      "outputs": [],
      "source": [
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
        "    return  image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nrDR8CnwrVk"
      },
      "source": [
        "Now shuffle and batch the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAEUG7vawxLm"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32 #@param {type:\"integer\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHEC9mbswxvM"
      },
      "outputs": [],
      "source": [
        "train_batches = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "test_batches = test_examples.map(format_image).batch(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghQhZjgEw1cK"
      },
      "source": [
        "Inspect a batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz0xsMCjwx54"
      },
      "outputs": [],
      "source": [
        "for image_batch, label_batch in train_batches.take(1):\n",
        "    pass\n",
        "\n",
        "image_batch.shape\n",
        "# The first parameter, 32, is the batch size, and the 224 by 224 by 3 defines the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS_gVStowW3G"
      },
      "source": [
        "## Defining the Model\n",
        "\n",
        "All it takes is to put a linear classifier on top of the `feature_extractor_layer` with the Hub module.\n",
        "\n",
        "For speed, we start out with a non-trainable `feature_extractor_layer`, but you can also enable fine-tuning for greater accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RaJW3XrPyFiF"
      },
      "outputs": [],
      "source": [
        "do_fine_tuning = False #@param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd0KfstqaUmE"
      },
      "source": [
        "Load TFHub Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svvDrt3WUrrm"
      },
      "outputs": [],
      "source": [
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   input_shape=IMAGE_SIZE + (3,), \n",
        "                                   output_shape=[FV_SIZE],\n",
        "                                   trainable=do_fine_tuning)\n",
        "\n",
        "# Now we'll load the model from TensorFlow Hub. We'll call this our feature extractor, \n",
        "# where we're using everything but the last layer in the mobile net model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50FYNIb1dmJH"
      },
      "outputs": [],
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "# Now we'll create our model by taking the feature extractor and adding a new dense \n",
        "# layer with our number of classes, which is just two, cats and dogs after it.\n",
        "model = tf.keras.Sequential([\n",
        "        feature_extractor,\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvhaW-IAMO7i"
      },
      "outputs": [],
      "source": [
        "#@title (Optional) Unfreeze some layers\n",
        "# We can unfreeze some of the layers if we like, and also retrain them. \n",
        "# So in this case, 10 of the layers of the mobile net will be retrained. \n",
        "# You can experiment with this to see the impact of different values. \n",
        "\n",
        "NUM_LAYERS = 10 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "      \n",
        "if do_fine_tuning:\n",
        "    feature_extractor.trainable = True\n",
        "    \n",
        "    for layer in model.layers[-NUM_LAYERS:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "else:\n",
        "    feature_extractor.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2e5WupIw2N2"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f3yBUvkd_VJ"
      },
      "outputs": [],
      "source": [
        "if do_fine_tuning:\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.002, momentum=0.9),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "else:\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_YKX2Qnfg6x"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "hist = model.fit(train_batches,\n",
        "                 epochs=EPOCHS,\n",
        "                 validation_data=validation_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_psFoTeLpHU"
      },
      "source": [
        "## Export the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaSb5nVzHcVv"
      },
      "outputs": [],
      "source": [
        "CATS_VS_DOGS_SAVED_MODEL = \"exp_saved_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZqRAg1uz1Nu"
      },
      "source": [
        "Export the SavedModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJMue5YgnwtN"
      },
      "outputs": [],
      "source": [
        "tf.saved_model.save(model, CATS_VS_DOGS_SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOQF4cOan0SY"
      },
      "outputs": [],
      "source": [
        "%%bash -s $CATS_VS_DOGS_SAVED_MODEL\n",
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY7QGBgBytwX"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(CATS_VS_DOGS_SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIhPyMISz952"
      },
      "outputs": [],
      "source": [
        "print(list(loaded.signatures.keys()))\n",
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_input_signature)\n",
        "print(infer.structured_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxLiLC8n0H16"
      },
      "source": [
        "## Convert Using TFLite's Converter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aUYvCpfWmrQ"
      },
      "source": [
        "Load the TFLiteConverter with the SavedModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqJRyIg8Wl1n"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(CATS_VS_DOGS_SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AudcNjT0UtfF"
      },
      "source": [
        "### Post-Training Quantization\n",
        "The simplest form of post-training quantization quantizes weights from floating point to 8-bits of precision. This technique is enabled as an option in the TensorFlow Lite converter. At inference, weights are converted from 8-bits of precision to floating point and computed using floating-point kernels. This conversion is done once and cached to reduce latency.\n",
        "\n",
        "To further improve latency, hybrid operators dynamically quantize activations to 8-bits and perform computations with 8-bit weights and activations. This optimization provides latencies close to fully fixed-point inference. However, the outputs are still stored using floating point, so that the speedup with hybrid ops is less than a full fixed-point computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmSr2-yZoUhz"
      },
      "outputs": [],
      "source": [
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpCijI08UxP0"
      },
      "source": [
        "### Post-Training Integer Quantization\n",
        "We can get further latency improvements, reductions in peak memory usage, and access to integer only hardware accelerators by making sure all model math is quantized. To do this, we need to measure the dynamic range of activations and inputs with a representative data set. You can simply create an input data generator and provide it to our converter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clM_dTIkWdIa"
      },
      "outputs": [],
      "source": [
        "def representative_data_gen():\n",
        "    for input_value, _ in test_batches.take(100):\n",
        "        yield [input_value]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oPkAxDvUias"
      },
      "outputs": [],
      "source": [
        "converter.representative_dataset = representative_data_gen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGUAVTqXVfnu"
      },
      "source": [
        "The resulting model will be fully quantized but still take float input and output for convenience.\n",
        "\n",
        "Ops that do not have quantized implementations will automatically be left in floating point. This allows conversion to occur smoothly but may restrict deployment to accelerators that support float. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPVdjaEJVkHy"
      },
      "source": [
        "### Full Integer Quantization\n",
        "\n",
        "To require the converter to only output integer operations, one can specify:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQi1aO2cVhoL"
      },
      "outputs": [],
      "source": [
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snwssESbVtFw"
      },
      "source": [
        "### Finally convert the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUEgr46WVsqd"
      },
      "outputs": [],
      "source": [
        "tflite_model = converter.convert()\n",
        "tflite_model_file = 'converted_model.tflite'\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbTF6nd1KG2o"
      },
      "source": [
        "## Test the TFLite Model Using the Python Interpreter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg2NkVTmLUdJ"
      },
      "outputs": [],
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "  \n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snJQVs9JNglv"
      },
      "outputs": [],
      "source": [
        "# Gather results for the randomly sampled test images\n",
        "predictions = []\n",
        "\n",
        "test_labels, test_imgs = [], []\n",
        "for img, label in tqdm(test_batches.take(10)):\n",
        "    interpreter.set_tensor(input_index, img)\n",
        "    interpreter.invoke()\n",
        "    predictions.append(interpreter.get_tensor(output_index))\n",
        "    \n",
        "    test_labels.append(label.numpy()[0])\n",
        "    test_imgs.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YMTWNqPpNiAI"
      },
      "outputs": [],
      "source": [
        "#@title Utility functions for plotting\n",
        "# Utilities for plotting\n",
        "\n",
        "class_names = ['cat', 'dog']\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    img = np.squeeze(img)\n",
        "\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "    \n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    \n",
        "    if predicted_label == true_label:\n",
        "        color = 'green'\n",
        "    else:\n",
        "        color = 'red'\n",
        "    \n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                         100*np.max(predictions_array),\n",
        "                                         class_names[true_label]), color=color)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK_CTyL3XQt1"
      },
      "source": [
        "NOTE: Colab runs on server CPUs. At the time of writing this, TensorFlow Lite doesn't have super optimized server CPU kernels. For this reason post-training full-integer quantized models  may be slower here than the other kinds of optimized models. But for mobile CPUs, considerable speedup can be observed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1-lbnicPNkZs"
      },
      "outputs": [],
      "source": [
        "#@title Visualize the outputs { run: \"auto\" }\n",
        "index = 0 #@param {type:\"slider\", min:0, max:9, step:1}\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(index, predictions, test_labels, test_imgs)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmZRieHmKLY5"
      },
      "source": [
        "Create a file to save the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMIjdLOsMO7v"
      },
      "outputs": [],
      "source": [
        "labels = ['cat', 'dog']\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "    f.write('\\n'.join(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eqPI2WaMO7v"
      },
      "source": [
        "If you are running this notebook in a Colab, you can run the cell below to download the model and labels to your local disk.\n",
        "\n",
        "**Note**: If the files do not download when you run the cell, try running the cell a second time. Your browser might prompt you to allow multiple files to be downloaded. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jJAxrQB2VFw"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('converted_model.tflite')\n",
        "    files.download('labels.txt')\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDlmpjC6VnFZ"
      },
      "source": [
        "# Prepare the Test Images for Download (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1ja_WA0WZOH"
      },
      "source": [
        "This part involves downloading additional test images for the Mobile Apps only in case you need to try out more samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzLKEBrfTREA"
      },
      "outputs": [],
      "source": [
        "!mkdir -p test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn7ukNQCSewb"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "for index, (image, label) in enumerate(test_batches.take(50)):\n",
        "    image = tf.cast(image * 255.0, tf.uint8)\n",
        "    image = tf.squeeze(image).numpy()\n",
        "    pil_image = Image.fromarray(image)\n",
        "    pil_image.save('test_images/{}_{}.jpg'.format(class_names[label[0]], index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVKKWUG8UMO5"
      },
      "outputs": [],
      "source": [
        "!ls test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_w_-UdlS9Vi"
      },
      "outputs": [],
      "source": [
        "!zip -qq cats_vs_dogs_test_images.zip -r test_images/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uzX0MO5MO7x"
      },
      "source": [
        "If you are running this notebook in a Colab, you can run the cell below to download the Zip file with the images to your local disk. \n",
        "\n",
        "**Note**: If the Zip file does not download when you run the cell, try running the cell a second time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Giva6EHwWm6Y"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    files.download('cats_vs_dogs_test_images.zip')\n",
        "except:\n",
        "    pass"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "C2_W1_Lab_2_Transfer_Learning.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
