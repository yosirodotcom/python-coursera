{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-2-public/blob/adding_C2/C2/W2/assignment_optional/C2_W2_Assignment_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8-Nr5k11fh"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Eq10uEbw0E4l"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYM61xrTsP5d"
      },
      "source": [
        "# Rock, Paper & Scissors with TensorFlow Hub - TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWFpUd1yy3gt"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 2,
=======
      "execution_count": 1,
>>>>>>> 61f52de65b996687217c6b23b16cc6c68eb80357
      "metadata": {
        "id": "110fGB18UNJn"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-hub\n",
            "  Obtaining dependency information for tensorflow-hub from https://files.pythonhosted.org/packages/6e/1a/fbae76f4057b9bcdf9468025d7a8ca952dec14bfafb9fc0b1e4244ce212f/tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata\n",
            "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy>=1.12.0 in g:\\myvenv\\python-coursera\\lib\\site-packages (from tensorflow-hub) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in g:\\myvenv\\python-coursera\\lib\\site-packages (from tensorflow-hub) (3.20.3)\n",
            "Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n",
            "   ---------------------------------------- 0.0/85.4 kB ? eta -:--:--\n",
            "   -------------------------------------- - 81.9/85.4 kB 1.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 85.4/85.4 kB 1.6 MB/s eta 0:00:00\n",
            "Installing collected packages: tensorflow-hub\n",
            "Successfully installed tensorflow-hub-0.15.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade tensorflow-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
=======
      "execution_count": 2,
>>>>>>> 61f52de65b996687217c6b23b16cc6c68eb80357
      "metadata": {
        "id": "dlauq-4FWGZM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "• Using TensorFlow Version: 2.14.0\n",
            "• Using TensorFlow Hub Version:  0.15.0\n",
            "WARNING:tensorflow:From C:\\Users\\YOSIRONADI\\AppData\\Local\\Temp\\ipykernel_19088\\656865381.py:11: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
=======
            "• Using TensorFlow Version: 2.7.0\n",
            "• Using TensorFlow Hub Version:  0.12.0\n",
            "WARNING:tensorflow:From C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_11844\\656865381.py:11: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
>>>>>>> 61f52de65b996687217c6b23b16cc6c68eb80357
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "• GPU Device Not Found. Running on CPU\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)\n",
        "print(\"\\u2022 Using TensorFlow Hub Version: \", hub.__version__)\n",
        "print('\\u2022 GPU Device Found.' if tf.test.is_gpu_available() else '\\u2022 GPU Device Not Found. Running on CPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmaHHH7Pvmth"
      },
      "source": [
        "## Select the Hub/TF2 Module to Use\n",
        "\n",
        "Hub modules for TF 1.x won't work here, please use one of the selections provided."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 4,
=======
      "execution_count": 3,
>>>>>>> 61f52de65b996687217c6b23b16cc6c68eb80357
      "metadata": {
        "id": "FlsEcKVeuCnf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with input size (224, 224) and output dimension 1280\n"
          ]
        }
      ],
      "source": [
        "module_selection = (\"mobilenet_v2\", 224, 1280) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYUsgwCBv87A"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nqVX3KYwGPh"
      },
      "source": [
        "Use [TensorFlow Datasets](http://tensorflow.org/datasets) to load the `rock_paper_scissors` dataset.\n",
        "\n",
        "This `tfds` package is the easiest way to load pre-defined data. If you have your own data, and are interested in importing using it with TensorFlow see [loading image data](../load_data/images.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": null,
      "metadata": {
        "id": "jGvpkDj4wBup"
      },
      "outputs": [],
=======
      "execution_count": 7,
      "metadata": {
        "id": "jGvpkDj4wBup"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'core' from partially initialized module 'tensorflow_datasets' (most likely due to a circular import) (c:\\Users\\ASUS\\Documents\\pythonenv\\python-coursera\\lib\\site-packages\\tensorflow_datasets\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\ASUS\\Documents\\repos\\python-coursera\\deploy\\C2_Device-based-TF-lite\\W2\\assignment_optional\\C2_W2_Assignment_Solution.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/repos/python-coursera/deploy/C2_Device-based-TF-lite/W2/assignment_optional/C2_W2_Assignment_Solution.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfds\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/repos/python-coursera/deploy/C2_Device-based-TF-lite/W2/assignment_optional/C2_W2_Assignment_Solution.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tfds\u001b[39m.\u001b[39mdisable_progress_bar()\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\Documents\\pythonenv\\python-coursera\\lib\\site-packages\\tensorflow_datasets\\__init__.py:43\u001b[0m\n\u001b[0;32m     41\u001b[0m _TIMESTAMP_IMPORT_STARTS \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mabsl\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[1;32m---> 43\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogging\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_tfds_logging\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogging\u001b[39;00m \u001b[39mimport\u001b[39;00m call_metadata \u001b[39mas\u001b[39;00m _call_metadata\n\u001b[0;32m     46\u001b[0m _metadata \u001b[39m=\u001b[39m _call_metadata\u001b[39m.\u001b[39mCallMetadata()\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'core' from partially initialized module 'tensorflow_datasets' (most likely due to a circular import) (c:\\Users\\ASUS\\Documents\\pythonenv\\python-coursera\\lib\\site-packages\\tensorflow_datasets\\__init__.py)"
          ]
        }
      ],
>>>>>>> 61f52de65b996687217c6b23b16cc6c68eb80357
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkF4Boe5wN7N"
      },
      "source": [
        "The `tfds.load` method downloads and caches the data, and returns a `tf.data.Dataset` object. These objects provide powerful, efficient methods for manipulating data and piping it into your model.\n",
        "\n",
        "Dividing the `train` split of this dataset into (train, validation, test) with 80%, 10%, 10% of the data respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ9xK9F2wGD8"
      },
      "outputs": [],
      "source": [
        "(train_examples, validation_examples, test_examples), info = tfds.load('rock_paper_scissors',\n",
        "                                                                       with_info=True, \n",
        "                                                                       as_supervised=True, \n",
        "                                                                       split=['train[:80%]',\n",
        "                                                                              'train[80%:90%]',\n",
        "                                                                              'train[90%:]'])\n",
        "\n",
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXQYXNWwf19"
      },
      "source": [
        "### Format the Data\n",
        "\n",
        "Use the `tf.image` module to format the images for the task.\n",
        "\n",
        "Resize the images to a fixes input size, and rescale the input channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7UyXblSwkUS"
      },
      "outputs": [],
      "source": [
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
        "    return  image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nrDR8CnwrVk"
      },
      "source": [
        "Now shuffle and batch the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAEUG7vawxLm"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32 #@param {type:\"integer\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHEC9mbswxvM"
      },
      "outputs": [],
      "source": [
        "train_batches = train_examples.shuffle(num_examples // 4).batch(BATCH_SIZE).map(format_image).prefetch(1)\n",
        "validation_batches = validation_examples.batch(BATCH_SIZE).map(format_image).prefetch(1)\n",
        "test_batches = test_examples.batch(1).map(format_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghQhZjgEw1cK"
      },
      "source": [
        "Inspect a batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz0xsMCjwx54"
      },
      "outputs": [],
      "source": [
        "for image_batch, label_batch in train_batches.take(1):\n",
        "    pass\n",
        "\n",
        "image_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS_gVStowW3G"
      },
      "source": [
        "## Defining the Model\n",
        "\n",
        "All it takes is to put a linear classifier on top of the `feature_extractor_layer` with the Hub module.\n",
        "\n",
        "For speed, we start out with a non-trainable `feature_extractor_layer`, but you can also enable fine-tuning for greater accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RaJW3XrPyFiF"
      },
      "outputs": [],
      "source": [
        "do_fine_tuning = False #@param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90DUQi59NXd4"
      },
      "outputs": [],
      "source": [
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   input_shape=IMAGE_SIZE + (3,), \n",
        "                                   output_shape=[FV_SIZE],\n",
        "                                   trainable=do_fine_tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MoRX4MsNXd5"
      },
      "outputs": [],
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        feature_extractor,\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SaXakrGNXd5"
      },
      "outputs": [],
      "source": [
        "#@title (Optional) Unfreeze some layers\n",
        "NUM_LAYERS = 10 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "      \n",
        "if do_fine_tuning:\n",
        "    feature_extractor.trainable = True\n",
        "    \n",
        "    for layer in model.layers[-NUM_LAYERS:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "else:\n",
        "    feature_extractor.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2e5WupIw2N2"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f3yBUvkd_VJ"
      },
      "outputs": [],
      "source": [
        "if do_fine_tuning:\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.002, momentum=0.9),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "else:\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_YKX2Qnfg6x"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "hist = model.fit(train_batches,\n",
        "                 epochs=EPOCHS,\n",
        "                 validation_data=validation_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_psFoTeLpHU"
      },
      "source": [
        "## Export the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaSb5nVzHcVv"
      },
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "RPS_SAVED_MODEL = \"rps_saved_model\""
=======
        "RPS_SAVED_MODEL = \"rps_saved_model\" # This variable contains the directory path where the SavedModel is saved."
>>>>>>> 61f52de65b996687217c6b23b16cc6c68eb80357
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZqRAg1uz1Nu"
      },
      "source": [
        "Export the SavedModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJMue5YgnwtN"
      },
      "outputs": [],
      "source": [
        "tf.saved_model.save(model, RPS_SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOQF4cOan0SY"
      },
      "outputs": [],
      "source": [
        "%%bash -s $RPS_SAVED_MODEL\n",
<<<<<<< HEAD
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
=======
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default\n",
        "'''\n",
        "it will display information about the SavedModel, including details about the inputs, outputs, \n",
        "and signature definition. This can be useful for verifying that the SavedModel was saved \n",
        "correctly and understanding how to interact with it when serving or deploying the model.\n",
        "'''"
>>>>>>> 61f52de65b996687217c6b23b16cc6c68eb80357
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY7QGBgBytwX"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(RPS_SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIhPyMISz952"
      },
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "print(list(loaded.signatures.keys()))\n",
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_input_signature)\n",
        "print(infer.structured_outputs)"
=======
        "print(list(loaded.signatures.keys())) #This line prints the list of signature keys available in the loaded SavedModel. In this case, there is one signature key, which is 'serving_default'.\n",
        "infer = loaded.signatures[\"serving_default\"] #This line retrieves the signature named 'serving_default' from the loaded SavedModel.\n",
        "print(infer.structured_input_signature) #This line prints the structured input signature of the selected signature. The output shows that the input to the model is a tensor named 'keras_layer_input' with a shape of (None, 224, 224, 3).\n",
        "print(infer.structured_outputs) # This line prints the structured outputs of the selected signature. The output shows that the output of the model is a tensor named 'dense' with a shape of (None, 3)"
>>>>>>> 61f52de65b996687217c6b23b16cc6c68eb80357
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxLiLC8n0H16"
      },
      "source": [
        "## Convert Using TFLite's Converter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmSr2-yZoUhz"
      },
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "converter = tf.lite.TFLiteConverter.from_saved_model(RPS_SAVED_MODEL)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()"
=======
        "converter = tf.lite.TFLiteConverter.from_saved_model(RPS_SAVED_MODEL) # The code you provided is using TensorFlow Lite's TFLiteConverter to convert a SavedModel to TensorFlow Lite format.\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE] # This line sets the optimization strategy for the TensorFlow Lite Converter to optimize for size. The tf.lite.Optimize.OPTIMIZE_FOR_SIZE option is used to enable size optimization, which aims to reduce the size of the resulting TensorFlow Lite model. Size-optimized models are particularly useful in scenarios where memory or storage constraints are critical, such as deploying models on mobile devices or edge devices.\n",
        "tflite_model = converter.convert() # This line converts the loaded TensorFlow model (previously loaded using TFLiteConverter.from_saved_model()) to a TensorFlow Lite model. The convert() method performs the actual conversion, and the resulting tflite_model is a binary representation of the model in TensorFlow Lite format."
>>>>>>> 61f52de65b996687217c6b23b16cc6c68eb80357
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMSyVdSdNXed"
      },
      "outputs": [],
      "source": [
        "tflite_model_file = 'converted_model.tflite'\n",
        "\n",
<<<<<<< HEAD
        "with open(tflite_model_file, \"wb\") as f:\n",
        "    f.write(tflite_model)"
=======
        "with open(tflite_model_file, \"wb\") as f: # This line opens the specified file ('converted_model.tflite') in binary write mode (\"wb\"). The file will be created if it does not exist, and if it already exists, its contents will be overwritten.\n",
        "    f.write(tflite_model) # This line writes the binary representation of the TensorFlow Lite model (tflite_model) to the opened file."
>>>>>>> 61f52de65b996687217c6b23b16cc6c68eb80357
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbTF6nd1KG2o"
      },
      "source": [
        "## Test the TFLite Model Using the Python Interpreter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg2NkVTmLUdJ"
      },
      "outputs": [],
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "with open(tflite_model_file, 'rb') as fid:\n",
        "    tflite_model = fid.read()\n",
        "    \n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snJQVs9JNglv"
      },
      "outputs": [],
      "source": [
        "# Gather results for the randomly sampled test images\n",
        "predictions = []\n",
        "\n",
        "test_labels, test_imgs = [], []\n",
        "for img, label in tqdm(test_batches.take(10)):\n",
        "    interpreter.set_tensor(input_index, img)\n",
        "    interpreter.invoke()\n",
        "    predictions.append(interpreter.get_tensor(output_index))\n",
        "    \n",
        "    test_labels.append(label.numpy()[0])\n",
        "    test_imgs.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YMTWNqPpNiAI"
      },
      "outputs": [],
      "source": [
        "#@title Utility functions for plotting\n",
        "# Utilities for plotting\n",
        "\n",
        "class_names = ['rock', 'paper', 'scissors']\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    img = np.squeeze(img)\n",
        "    \n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "    \n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    \n",
        "    print(type(predicted_label), type(true_label))\n",
        "    \n",
        "    if predicted_label == true_label:\n",
        "        color = 'green'\n",
        "    else:\n",
        "        color = 'red'\n",
        "        \n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                         100*np.max(predictions_array),\n",
        "                                         class_names[true_label]), color=color)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-lbnicPNkZs"
      },
      "outputs": [],
      "source": [
        "#@title Visualize the outputs { run: \"auto\" }\n",
        "index = 0 #@param {type:\"slider\", min:0, max:9, step:1}\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(index, predictions, test_labels, test_imgs)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i2T2NnnNXek"
      },
      "source": [
        "Create a file to save the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RD7Sk5VNXek"
      },
      "outputs": [],
      "source": [
        "with open('labels.txt', 'w') as f:\n",
        "    f.write('\\n'.join(class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmZRieHmKLY5"
      },
      "source": [
        "If you are running this notebook in a Colab, you can run the cell below to download the model and labels to your local disk.\n",
        "\n",
        "**Note**: If the files do not download when you run the cell, try running the cell a second time. Your browser might prompt you to allow multiple files to be downloaded. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jJAxrQB2VFw"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('converted_model.tflite')\n",
        "    files.download('labels.txt')\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDlmpjC6VnFZ"
      },
      "source": [
        "# Prepare the Test Images for Download (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1ja_WA0WZOH"
      },
      "source": [
        "This part involves downloading additional test images for the Mobile Apps only in case you need to try out more samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzLKEBrfTREA"
      },
      "outputs": [],
      "source": [
        "!mkdir -p test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn7ukNQCSewb"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "for index, (image, label) in enumerate(test_batches.take(50)):\n",
        "    image = tf.cast(image * 255.0, tf.uint8)\n",
        "    image = tf.squeeze(image).numpy()\n",
        "    pil_image = Image.fromarray(image)\n",
        "    pil_image.save('test_images/{}_{}.jpg'.format(class_names[label[0]], index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVKKWUG8UMO5"
      },
      "outputs": [],
      "source": [
        "!ls test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_w_-UdlS9Vi"
      },
      "outputs": [],
      "source": [
        "!zip -qq rps_test_images.zip -r test_images/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_7FfE5NNXem"
      },
      "source": [
        "If you are running this notebook in a Colab, you can run the cell below to download the Zip file with the images to your local disk. \n",
        "\n",
        "**Note**: If the Zip file does not download when you run the cell, try running the cell a second time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Giva6EHwWm6Y"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    files.download('rps_test_images.zip')\n",
        "except:\n",
        "    pass"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "C2_W2_Assignment_Solution.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
